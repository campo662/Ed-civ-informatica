# Rischi etici dell'intelligenza artificiale

## Introduzione

E’ indubbio che l’intelligenza artificiale porti con sè una quantità spropositata di dilemmi etici. Alcuni riguardano l’appiattimento cognitivo e la standardizzazione dell’individuo; c’è chi parla di fine delle democrazie, chi vede l’insediamento del “Big Brother” di Orwell, o ancora, per i più drastici, l’inizio della fine della storia dell’umanità e l’insediamento di una dittatura robotica. 

Tutti temi caldi e discussi oggigiorno, ma forse non abbastanza. 

Questo testo ha l’obiettivo di solleticare la curiosità nell’approfondire questi temi, trattati qui in ristretto numero rispetto alla quantità dei disponibili, e di seminare la possibilità di qualche riflessione personale.

---

## che cos’è l’IA

_ _ Dal Forno _ _ 

- che cosa si intende per ai (che cosa vuol dire intelligenza, che cosa si intende, …)
- come e nata (algoritmi di tanto tempo fa limitazione tecnologia ora raggiunta)
- test di Turing 
- come funziona la generazione dell’output
- large language models
- differenze ai generativa con le altre 
- come si prevede il futuro
- commissioni etiche per la gestione strumento con aggancio alla questione etica in seguito

Il termine Intelligenza Artificiale (IA) non ha una definizione univoca e universalmente accettata, ma viene generalmente inteso come la proprietà di una macchina di imitare o simulare, in tutto o in parte, l'intelligenza biologica. La sua nascita ufficiale risale al 1955, quando John McCarthy e altri ricercatori ipotizzarono che ogni aspetto dell'apprendimento o dell'intelligenza potesse essere descritto così precisamente da poter costruire una macchina capace di simularlo.

---

# Dilemma etico: come l’IA condiziona e modifica le relazioni

Come detto nell’introduzione, ci sarebbero molti argomenti da trattare, ma ci concentreremo solamente nel come l’intelligenza artificiale modifichi e fossilizzi le relazioni interpersonali. Riporteremo a piè di pagina le fonti alle quali abbiamo attinto per formulare le nostre conclusioni e i nostri ragionamenti.

---

## Relazioni interpersonali: la prima vittima dell’AI

Le relazioni interpersonali sono alla base della società, e la società è la base della vita di un individuo. Quindi è possibile affermare che una persona senza interazioni sociali non vive in una società, ma anzi una persona senza interazioni sia una persona vuota, priva del senso di vivere. 

Pensare concretamente all’esistenza di una figura del genere nella nostra società, fino a poco tempo fa sarebbe stato impossibile, ma con l’approdo di internet nella vita delle persone, si sono iniziati a vedere i primi effetti di un’alienazione sociale. 

Gli individui affetti da questo fenomeno psicosociale vengono chiamati Hikikomori, e i numeri degli stessi, cresciuti negli anni a dismisura, hanno iniziato a preoccupare. “Il 2,1% del campione attribuisce a sé stesso la definizione di Hikikomori. Proiettando il dato sulla popolazione studentesca* 15-19enne a livello nazionale, si può quindi stimare che circa 54.000 studenti italiani di scuola superiore si identifichino in una situazione di “ritiro sociale”, riprendendo le parole di Sabrina Molinaro, ricercatrice del Cnr-Ifc, riportate in “Il ritiro sociale volontario tra i giovani in Italia | Consiglio Nazionale delle Ricerche”.

Quanto viene fatto per il reinserimento sociale di queste persone, almeno in Italia, è decisamente poco: le campagne mediatiche evitano il problema e la “moda” dell’informazione, almeno per ora, lascia spenti i riflettori su questa piaga sociale.

Solo recentemente è comparsa qualche campagna ministeriale sui principali canali televisivi, che si preoccupa di lanciare un timido messaggio in merito a questa questione, ma per il resto è silenzio più totale.

La situazione è già grave di per sé, ma come se non bastasse, sono stati introdotti nel mercato i chatbot AI.

Ma perché i chatbot rappresentano un problema?

Sarebbe disonestà intellettuale affermare che i chatbot sono una creazione cattiva ed inutile, ma rispetto al problema dell’isolamento sono di certo un’aggravante.

Le intelligenze artificiali, come Chat GPT, Claude e Gemini, citando le più conosciute, si pongono all’utente come creature pensanti, intelligenti e consce, stranamente sempre d’accordo con le tesi e le idee che vengono date in pasto all’algoritmo, e nelle risposte calme ed empatiche. Per non parlare della sfilza di complimenti che precede ogni risposta, i quali inneggiano l’intelligenza e l’acutezza dell’utente; e nella risposta stessa citazioni di frasi scritte come prompt, come a dire “utente, non avrei saputo dire di meglio, ricito quanto hai detto perché è perfetto”.

Questo teatrino generato e modellato in funzione del consumatore è studiato nei minimi dettagli per invogliare l’utente a continuare a scrivere con gli llm. Lo stesso principio per il quale le slot machine o i casinò cercano di trattenere il più tempo possibile lo scommettitore con loro. 

Il fine ultimo sono sempre e solo i soldi. 

Ma in realtà, pensandoci, tutto questo è puramente logico ed intuitivo: chi mai vorrebbe un dialogo con un chatbot con limiti, spesso svogliato o distratto, stanco, che non capisce, che giudica, e fa notare dove si commettono errori, anche in modo sgarbato? O anzi, lanciando una provocazione ancora più acuminata: chi preferirebbe una persona, che per natura possiede tutti questi limiti, quando posso avere un llm che la imita in tutto e per tutto ed in più che finge di conoscermi, apparentemente migliore, e per giunta 24 ore su 24?

Pensare che le due cose siano la stessa cosa, o il chatbot la versione migliorata della persona, o ancora peggio che le interazioni che si instaurano nei due scenari si equivalgano, è indicibile. 

Questo perché una relazione tra umani è ruvida, è difficile: io devo capire l’altro, capire come pormi, capire quanto osare e come esprimermi, e l’altro deve fare la stessa cosa. E’ difficile, e per riuscire a conversare in maniera efficace e positiva, ci vuole molto tempo ed allenamento, e soprattutto molte interazioni.

Per parlare ad un chatbot, invece, ci si può rivolgere come si vuole, insultando, criticando, uccidendo emotivamente l’ipotetica persona che avrebbe risposto nella stessa maniera.

Si tratta quindi di una relazione liscia, facile, in più che appaga, poiché ho sempre ragione in qualche modo e per di più sono molto intelligente. 

Approfondiamo questa cosa: tutti bene o male cerchiamo di attribuirci queste due qualità nella vita, e se qualcuno lo conferma in un modo o nell’altro instauriamo con quest’ultimo un rapporto privilegiato, anche se, in questo caso, puramente unilaterale.

Si è propensi ad instaurare questo rapporto preferenziale poiché siamo continuamente in cerca di qualcuno che la pensi come noi. Questa dipendenza prende il nome di bias di conferma, ed è proprio questo il cardine sul quale tutte le conversazioni con llm ruotano.

Questo è un grave problema, perché tornando agli hikikomori di prima, che si nascondono e si isolano dalla società per fuggire dalla difficoltà che la vita porta con sé, l’intelligenza artificiale, con queste caratteristiche propriamente utopiche, può rappresentare la loro droga e la loro causa emarginazione più totale.

Ma più delle persone che già sono affette da questa sindrome, quello che dovrebbe preoccupare ancora di più sono tutte le persone fragili che possono incombere in questo “paese dei balocchi”. Cercando una provocazione più marcata, in realtà tutti dovremmo avere timore di incappare in questo baratro sociale: basti pensare che un periodo di crisi nella vita può mettere nella situazione di rientrare nella categoria di persone fragili, poiché lasciarsi andare ed abusare del supporto vacuo che l’intelligenza artificiale offre è un diavolo tentatore.

Prendendo in esame il film “Lei” del 2013, si può notare che il mondo descritto e che allora sembrava pura fantascienza, ora non è più una realtà così remota. Il film infatti tratta di un mondo distopico dove l’IA diventa entità presente e viva nella vita dell’uomo, seduttrice e perfetta. E’ proprio questa perfezione che induce il protagonista ad abbandonarsi della stessa, finendo per innamorarsi di un ente senza corporeità, dando vita a situazioni imbarazzanti e divertenti, ma che fanno riflettere, inducendolo, infine, ad una sofferenza emotiva senza eguali nel momento in cui scopre che il principio di unicità che lega l’uomo alla macchina è strettamente legato alla natura della persona e non all’algoritmo.

---

# Fonti

- The AI-Generated Intimacy Crisis | Bryony Cole | TED
- Relazione interpersonale - Wikipedia
- Hikikomori - Wikipedia
- Il ritiro sociale volontario tra i giovani in Italia | Consiglio Nazionale delle Ricerche
- Hikikomori: una generazione che si ritira, una società che non ascolta - la Repubblica
- Persona (filosofia) - Wikipedia
- Bias di conferma - Wikipedia
- Lei (film 2013) - Wikipedia
- Rick DuFer - YouTube
- Ciao Internet con Matteo Flora - YouTube
- TED - YouTube
- Kurzgesagt – In a Nutshell - YouTube

---

# Citazioni

> “E’ la capacità di un  
> individuo di riconoscere le  
> proprie emozioni e quelle  
> degli altri, di saperle  
> comunicare attraverso le  
> espressioni e il  
> linguaggio della propria  
> cultura e di regolarle  
> in modo adeguato al  
> contesto, così da  
> ricavare un senso di  
> efficacia dagli scambi  
> interattivi”  
> (Saarni, 1999).

---

## L’Intelligenza Emotiva (Goleman)

L’Intelligenza Emotiva (Goleman) è la capacità di riconoscere i nostri sentimenti e quelli delle persone che ci circondano , di motivare noi stessi gestendo positivamente le nostre emozioni, tanto interiormente quanto nelle nostre relazioni.

A differenza dell’intelligenza che veniva misurata con il QI, basata principalmente da abilità linguistiche e matematiche, che è un dato poco variabile nella nostra vita (tende a stabilizzarsi intorno ai 16 anni ), L’INTELLIGENZA EMOTIVA PUÒ ESSERE CONTINUAMENTE ALIMENTATA ed il nostro QE (quoziente emotivo) può crescere senza limiti se opportunamente allenato.

Lavorarci comporta il seguire un approccio “Inside Out”, ovvero

DA DENTRO VERSO FUORI.
